test.connection.success=Test Connection Successfully
assign.menu.failed=Assign Menu Failed
ldap.user.autoload.forbaid=Auto-mapping LDAP users are not enabled, please contact your administrator to import
cluster.instance.recycle.success=Recycle Success
execute.failed=Execute Failed
ldap.user.duplicat=The ldap matches to multiple user data
git.branch.not.found=Git Branch Not Found
copy.success=Copy Successfully
user.superadmin.cannot.disable=User SuperAdmin Cannot Disable
ds.work.flow.not.save=Please Save Workflow First
schedule.status.unknown=Unknown Status: {0}
user.binding.role.delete.all=User Binding Role Delete All
modify.failed=Update Failed
git.build.success=Git Build Success
menu.has.child=Menu Has Child, Can Not Delete
tenant.already.exists=Tenant Already Exists
save.failed=Save Failed
assign.menu.success=Assign Menu Success
user.disabled.by.admin=The Current User is Disabled By Admin
select.menu=Please Select Menu
role.not.exist=Role Not Exists
delete.success=Delete Successfully
clear.success=Clear Successfully
move.success=Move Successfully
ldap.login.forbid=If the current user login mode is not LDAP, contact the administrator to modify it, or do not use LDAP to log in
request.params.not.valid.error=Request Parameter {0} Is Not Valid
change.password.failed=Change Password Failed
menu.name.exist=Menu Already Exists
ds.task.type.not.support=DolphinScheduler Type Is [{}] Not Support, Not DINKY Type
datasource.connect.normal=DataSource Connect Normal
restart.success=Restart Successfully
test.msg.job.log.url=Click to view the exception log for this task
user.assign.role.success=User Assign Role Success
global.params.check.error.value=Field: {0}, Illegal Value: {1}
change.password.success=Change Password Success
user.not.exist=User Not Exist
refresh.success=Refresh Successfully
ds.get.node.list.error=Get Node List Error
ldap.default.tenant.nofound=The LDAP default tenant does not exist
copy.failed=Copy Failed
folder.not.empty=Folder Not Empty, Can Not Delete
be.replaced=token has been pushed offline
datasource.connect.success=DataSource Connect Success
sign.out.success=Sign Out Successfully
added.success=Added Successfully
tenant.binding.user=Tenant Binding User , Can Not Delete
send.test.failed=Test Msg Send Fail
delete.failed=Delete Failed
role.binding.user=Role Already Binding User , Can Not Delete
not.token=Can Not Read Token
execute.success=Execute Successfully
token.freezed=token has been frozen
menu.has.assign=Menu Has Assign , Can Not Delete
datasource.status.refresh.success=DataSource Status Refresh Success
user.not.login=User is Not Login
tenant.assign.user.failed=Tenant Assign User Failed
stop.success=Stop Successfully
move.failed=Move Failed
get.tenant.failed=Get Tenant Info Failed
send.test.success=Test Msg Send Success
login.success=Login Successfully
login.password.not.null=Login Password Not Null
unknown.error=Unknown Error: {0}
stop.failed=Stop Failed
role.name.exist=Role Already Exists
ldap.filter.incorrect=If the user filter rule cannot be empty, enter the relevant configuration
tenant.assign.user.success=Tenant Assign User Success
ds.add.work.flow.definition.success=Add Workflow Definition Success
expired.token=Expired Token
refresh.failed=Refresh Failed
operate.success=Operate Successfully
git.project.not.found=Git Project Not Found
cluster.instance.heartbeat.success=Cluster Instance Heartbeat Success
ldap.no.user.found=The LDAP connection was successful, but it did not match to any users
login.failure=User Login Failure
request.params.error=Request Parameter Error
user.not.binding.tenant=User Not Binding Tenant
user.assign.role.failed=User Assign Role Failed
rename.failed=Rename Failed
test.msg.job.name=Job of Test
tenant.binding.user.delete.all=Tenant Binding User Delete All
menu.not.exist=Menu Not Exists
test.msg.job.name.title=Task
ds.task.not.exist=Task Not Exist
global.params.check.error=Field: {0}, {1}
test.msg.title=Real Time alarm mertics
user.name.passwd.error=UserName Or Password Not Correct
no.prefix=The token was not submitted according to the specified prefix
query.success=Query Successfully
ds.work.flow.definition.not.exist=Workflow Definition Not Exist
tenant.name.exist=Tenant Already Exists
failed=Failed
added.failed=Added Failed
task.not.exist=Task Not Exist
task.is.online= Task is online, modification is prohibited
cluster.instance.deploy=Deploy Success
clear.failed=Clear Failed
rename.success=Rename Successfully
job.release.disabled.update=Assignment Has Been Published, Modification is Prohibited
success=Successfully
tenant.not.exist=Tenant Not Exist
user.already.exists=User Already Exists
git.building=Git Building
ds.work.flow.definition.task.name.exist=Add Failed, Workflow Definition [{}] Already Exists Task Definition [{}] Please Refresh
role.already.exists=Role Already Exists
internal.server.error.args=Internal Server Error: {0}
kick.out=token has been kicked offline
restart.failed=Restart Failed
invalid.token=Invalid Token
datasource.not.exist=DataSource Not Exist
datasource.clear.cache.success=DataSource Clear Cache Success
tenant.admin.already.exists=Tenant Admin Already Exists, Only One Tenant Admin
ds.work.flow.definition.online=Workflow Definition [{}] Has Been Online
test.msg.job.url=Jump to the task
savepoint.is.null=Savepoint Is Null
git.sort.success=Git Sort Success
ds.add.task.definition.success=Add Task Definition Success
alert.group.exist=Alert Group Already Exists
git.sort.failed=Git Sort Failed
query.failed=Query Failed
save.success=Save Successfully
cluster.instance.kill=Kill Success
cluster.not.exist=Cluster Not Exist
operate.failed=Operate Failed
test.connection.failed=Test Connection Failed
switching.tenant.success=Select Tenant Success
tenant.name.not.exist=Tenant Not Exists
job.instance.not.exist=Job Instance Not Exist
modify.success=Update Successfully
user.old.password.incorrect=User Old Password Incorrect
ldap.user.incorrect=The LDAP user name (DN) Incorrect
role.binding.row.permission=Role Already Binding Row Permission , Can Not Delete

# dinky-admin
unknown.i18n=Unknown i18n information, please check. . .

file.upload.failed=File upload failed, reason: {0}

hdfs.init.failed=Internal hdfs client initialization error, reason: {0}
hdfs.file.lose=The core-site.xml/hdfs-site.xml/yarn-site.xml files were not found in the project root directory, please upload these files first



# dinky-alert
alert.rule.jobFail=Job Failure
alert.rule.getJobInfoFail=Get Job Info Fail
alert.rule.jobRestart=Job Restart
alert.rule.checkpointFail=Checkpoint Failure
alert.rule.jobRunException=Job Run Exception
alert.rule.checkpointTimeout=Checkpoint Timeout

daemon.task.config.not.exist=the thread task configuration can not be empty
daemon.task.not.support=threaded task types are notsupported


# system config
sys.flink.settings.useRestAPI=Use Rest API
sys.flink.settings.useRestAPI.note=Whether to use RestAPI when operating and maintaining Flink tasks
sys.flink.settings.sqlSeparator=SQL Separator
sys.flink.settings.sqlSeparator.note=SQL Separator
sys.flink.settings.jobIdWait=Job submission waiting time
sys.flink.settings.jobIdWait.note=Maximum waiting time (seconds) for obtaining Job ID when submitting Application or PerJob tasks
sys.maven.settings.settingsFilePath=Maven configuration file path
sys.maven.settings.settingsFilePath.note=Maven configuration file path, eg
sys.maven.settings.repository=Maven warehouse address
sys.maven.settings.repository.note=Maven warehouse address
sys.maven.settings.repositoryUser=Maven warehouse user name
sys.maven.settings.repositoryUser.note=Maven private server authentication user name
sys.maven.settings.repositoryPassword=Maven warehouse password
sys.maven.settings.repositoryPassword.note=Maven private server authentication password, please note
sys.env.settings.pythonHome=Python Env variables
sys.env.settings.pythonHome.note=Python Env variables
sys.env.settings.dinkyAddr=Dinky Address
sys.env.settings.dinkyAddr.note=The address must be the same as the address configured in the Dinky Application background url
sys.dolphinscheduler.settings.enable=Whether to enable DolphinScheduler
sys.dolphinscheduler.settings.enable.note=Whether to enable DolphinScheduler, the relevant functions of DolphinScheduler can only be used after it is enabled, please ensure that the relevant configuration of DolphinScheduler is correct
sys.dolphinscheduler.settings.url=DolphinScheduler address
sys.dolphinscheduler.settings.url.note=The address must be consistent with the address configured in the DolphinScheduler background, eg: http://127.0.0.1:12345/dolphinscheduler
sys.dolphinscheduler.settings.token=DolphinScheduler Token
sys.dolphinscheduler.settings.token.note=DolphinScheduler's Token, please create a token in DolphinScheduler's Security Center->Token Management, and fill in the configuration
sys.dolphinscheduler.settings.projectName=DolphinScheduler project name
sys.dolphinscheduler.settings.projectName.note=The project name specified in DolphinScheduler, case insensitive
sys.ldap.settings.url=ldap address of service
sys.ldap.settings.url.note=ldap address of service, eg: ldap://192.168.111.1:389
sys.ldap.settings.userDn=Login User name (DN)
sys.ldap.settings.userDn.note=User name for connecting to the ldap service, or the administrator DN
sys.ldap.settings.userPassword=login password
sys.ldap.settings.userPassword.note=Password used to connect to the ldap service
sys.ldap.settings.timeLimit=Connection Timeout
sys.ldap.settings.timeLimit.note=The maximum time to connect to the ldap service is disconnected
sys.ldap.settings.baseDn=BaseDn
sys.ldap.settings.baseDn.note=Dinky will conduct a user search on this base dn,eg: ou=users,dc=dinky,dc=com
sys.ldap.settings.filter=User filtering rules
sys.ldap.settings.filter.note=User filtering by using the filter syntax of the ldap, eg
sys.ldap.settings.autoload=User atically map users when logging in
sys.ldap.settings.autoload.note=When turned on, when a user logs in with LDAP, if there is no corresponding Dinky user mapping, the LDAP information is automatically pulled to create a Dinky user mapping to it. If this feature is closed, you will not be able to log in for unimported LDAP users
sys.ldap.settings.defaultTeant=The LDAP imports the default tenant code
sys.ldap.settings.defaultTeant.note=After opening the automatic import of users, the new user login needs a default tenant code, otherwise it cannot log in
sys.ldap.settings.castUsername=The LDAP user-name segment
sys.ldap.settings.castUsername.note=It is necessary to fill in the attribute field of the user in an LDAP to correspond to the Dinky user. Generally, cn or uid indicates the unique identity of the user
sys.ldap.settings.castNickname=The LDAP nickname field
sys.ldap.settings.castNickname.note=Need to fill in the attribute field of the user in an LDAP to correspond to the Dinky nickname, must be filled in, generally selected as sn or other identification, not required unique
sys.ldap.settings.enable=Whether to enable the ldap
sys.ldap.settings.enable.note=Turn the LDAP login function on
sys.metrics.settings.sys.enable=Dinky JVM Monitor switch
sys.metrics.settings.sys.enable.note=This switch is related to Dinky JVM Monitor, which determines the display of Dinky Server in the monitoring page and the collection of JVM Metrics
sys.metrics.settings.sys.gatherTiming=Dinky JVM Metrics collection time granularity
sys.metrics.settings.sys.gatherTiming.note=Dinky JVM Metrics collection time granularity, timed task interval trigger
sys.metrics.settings.flink.gatherTiming=Flink Metrics collection time granularity
sys.metrics.settings.flink.gatherTiming.note=Flink Metrics collection time granularity, scheduled task interval trigger
sys.metrics.settings.flink.gatherTimeout=Flink Metrics collection time granularity, scheduled task interval trigger
sys.metrics.settings.flink.gatherTimeout.note=Flink Metrics collection timeout period, scheduled task interval trigger (this configuration item should be smaller than Flink Metrics collection time granularity)
sys.resource.settings.base.enable=Whether to enable Resource
sys.resource.settings.base.enable.note=Enable resource management function. If you switch storage mode, you need to turn off this switch. After the relevant configuration is completed, turn it on again.
sys.resource.settings.base.upload.base.path=Root path of the upload directory
sys.resource.settings.base.upload.base.path.note=Resources are stored on the HDFS/OSS path. Resource files will be stored in this base path. Configure it by yourself. Please ensure that the directory exists on the relevant storage system and has read capabilities. Write permission. recommend
sys.resource.settings.base.model=Storage model
sys.resource.settings.base.model.note=Supports HDFS and OSS, it will take effect after switching the option, and resource files will be migrated at the same time.
sys.resource.settings.oss.endpoint=URL of the object storage service
sys.resource.settings.oss.endpoint.note=For example: https://oss-cn-hangzhou.aliyuncs.com
sys.resource.settings.oss.accessKey=Access key
sys.resource.settings.oss.accessKey.note=Access key is like a user ID that uniquely identifies your account
sys.resource.settings.oss.secretKey=Secret key
sys.resource.settings.oss.secretKey.note=Secret key is the password of your account
sys.resource.settings.oss.bucketName=Bucket name
sys.resource.settings.oss.bucketName.note=Default bucket name
sys.resource.settings.oss.region=region
sys.resource.settings.oss.region.note=region
sys.resource.settings.hdfs.root.user=HDFS operation user name
sys.resource.settings.hdfs.root.user.note=HDFS operation user name
sys.resource.settings.hdfs.fs.defaultFS=HDFS defaultFS
sys.resource.settings.hdfs.fs.defaultFS.note=fs.defaultFS configuration items, such as remote: hdfs://localhost:9000, local: file:///


#Dinky Gateway
gateway.kubernetes.test.failed= failed to test the Flink configuration:

task.status.is.not.done=In the current publishing state, a job is running and the online fails, please stop and go online
task.sql.explain.failed=SQL parsing failed, please check the SQL statement
task.update.failed=Task Update failed

# process
process.submit.submitTask= Submit the job
process.submit.checkSql=Check job
process.submit.execute = execute the job
process.submit.buildConfig=Build configuration information
process.submit.execute.commSql=excute commonSql
process.submit.execute.flinkSql=excute flinkSql


# resource
resource.root.dir.not.allow.delete=The root directory is not allowed to be deleted
resource.dir.or.file.not.exist=The directory or file does not exist