test.connection.success=测试连接成功
assign.menu.failed=分配菜单失败
ldap.user.autoload.forbaid=未开启自动映射LDAP用户，请联系管理员导入
cluster.instance.recycle.success=回收成功
execute.failed=执行失败
ldap.user.duplicat=ldap匹配到多个用户数据
git.branch.not.found=获取不到分支信息
copy.success=复制成功
user.superadmin.cannot.disable=超级管理员用户不能停用
user.superadmin.cannot.delete=超级管理员用户不能删除
ds.work.flow.not.save=请先保存工作流
schedule.status.unknown=未知状态: {0}
user.binding.role.delete.all=用户绑定角色删除所有
modify.failed=修改失败
git.build.success=预更新状态成功,开始执行构建流程
menu.has.child=存在子菜单 不允许删除
tenant.already.exists=租户已存在
save.failed=保存失败
assign.menu.success=分配菜单成功
user.disabled.by.admin=当前用户已被管理员停用
select.menu=请选择菜单
role.not.exist=角色不存在
delete.success=删除成功
clear.success=清除成功
move.success=移动成功
ldap.login.forbid=当前用户登录模式不是LDAP，请联系管理员修改,或不使用LDAP登录
ldap.login.test.success=LDAP 登录测试成功
request.params.not.valid.error=请求参数[{0}]无效
change.password.failed=修改密码失败
menu.name.exist=菜单已存在
ds.task.type.not.support=海豚调度类型为 [{}] 不支持,非DINKY类型
datasource.connect.normal=数据源连接正常
restart.success=重启成功
test.msg.job.log.url=点击查看该任务的异常日志
user.assign.role.success=用户分配角色成功
global.params.check.error.value=字段: {0}, 不合法的值: {1}
change.password.success=修改密码成功
user.not.exist=用户不存在
refresh.success=刷新成功
ds.get.node.list.error=节点获取失败
ldap.default.tenant.nofound=LDAP默认租户不存在
copy.failed=复制失败
folder.not.empty=该目录下存在子目录/作业，无法删除
be.replaced=token 已被顶下线
datasource.connect.success=数据源连接测试成功
sign.out.success=退出成功
added.success=新增成功
tenant.binding.user=删除租户失败，该租户已绑定用户
send.test.failed=测试信息发送失败
delete.failed=删除失败
role.binding.user=该角色已绑定用户，无法删除
not.token=未能读取到有效 Token
execute.success=执行成功
debug.success=调试成功
debug.failed=调试失败
publish.success=发布成功
publish.failed=发布失败
offline.success=下线成功
offline.failed=下线失败
version.rollback.success=版本回滚成功
version.rollback.failed=版本回滚失败
token.freezed=token 已被冻结
menu.has.assign=菜单已分配,不允许删除
datasource.status.refresh.success=数据源状态刷新成功
user.not.login=用户未登录
tenant.assign.user.failed=分配用户失败
stop.success=已成功停止
move.failed=移动失败
get.tenant.failed=获取租户信息失败
send.test.success=测试信息发送成功
login.success=登录成功
login.password.not.null=登录密码不能为空
unknown.error=未知异常: {0}
stop.failed=停止失败
role.name.exist=角色已存在
ldap.filter.incorrect=用户过滤规则不能为空，请填写相关配置
tenant.assign.user.success=分配用户成功
ds.add.work.flow.definition.success=添加工作流定义成功
expired.token=Token 已过期
refresh.failed=刷新失败
operate.success=操作成功
git.project.not.found=获取不到项目信息
cluster.instance.heartbeat.success=集群实例心跳成功
ldap.no.user.found=LDAP连接成功，但未匹配到任何用户
login.failure=用户登录失败
request.params.error=请求参数错误
user.not.binding.tenant=用户未绑定租户
user.assign.role.failed=用户分配角色失败
rename.failed=重命名失败
test.msg.job.name=测试任务
tenant.binding.user.delete.all=该租户绑定的用户已被全部删除
menu.not.exist=菜单不存在
test.msg.job.name.title=任务
ds.task.not.exist=任务不存在
global.params.check.error=字段: {0}, {1}
test.msg.title=实时告警监控
user.name.passwd.error=用户名或密码不正确
no.prefix=未按照指定前缀提交 token
query.success=查询成功
ds.work.flow.definition.not.exist=工作流定义不存在,你可以添加工作流定义
ds.work.flow.definition.process.update=工作流定义 [{}] 进行更新,TaskCode: [{}],参数 1: [{}],参数 2: [{}]
tenant.name.exist=租户已存在
failed=获取失败
added.failed=新增失败
task.not.exist=任务不存在
task.is.online=任务已上线，禁止修改
task.is.existed=作业已存在
task.is.publish.cannot.delete=作业已发布，无法删除,请先下线
task.is.running.cannot.delete=作业正在运行，无法删除,请先停止
job.alert.max.send.count=你配置了指定时间间隔[{}]秒内最大发送次数为：[{}]，当前时间在指定时间间隔前的时间区间内，且已经发送记录数为：[{}]，不发送告警消息
cluster.instance.deploy=部署完成
clear.failed=清除失败
rename.success=重命名成功
job.release.disabled.update=作业已发布，禁止修改
success=获取成功
tenant.not.exist=租户不存在
user.already.exists=用户名已存在
git.building=此任务正在构建
ds.work.flow.definition.task.name.exist=工作流定义 [{}] 已存在任务定义 [{}] , 将执行更新操作
role.already.exists=角色已存在
internal.server.error.args=服务端异常: {0}
kick.out=token 已被踢下线
restart.failed=重启失败
invalid.token=无效的 Token
datasource.not.exist=数据源不存在
datasource.clear.cache.success=清除库表缓存成功
datasource.exist.relationship=数据源已存在关联关系,不允许删除
tenant.admin.already.exists=已存在租户管理员, 租户超管只能有一个
ds.work.flow.definition.online=工作流定义 [{}] 已经上线
test.msg.job.url=跳转至该任务
savepoint.is.null=保存点为空
git.sort.success=排序成功
ds.add.task.definition.success=添加任务定义成功
alert.group.exist=告警组已存在
alert.group.exist.relationship=告警组已存在关联关系,不允许删除
alert.template.exist.relationship=告警模板已存在关联关系,不允许删除
git.sort.failed=排序失败
query.failed=查询失败
save.success=保存成功
cluster.instance.kill=已杀死该进程/集群
cluster.not.exist=集群不存在
cluster.instance.exist.relationship=集群实例已存在关联关系,不允许删除
cluster.instance.local.not.support.kill=Local 模式集群实例暂未实现停止功能
cluster.instance.not.health=集群实例状态不健康
cluster.instance.health.not.delete=集群实例为可用状态,不允许删除,请先停止该集群实例
cluster.config.exist.relationship=集群配置已存在关联关系,不允许删除
udf.template.exist.relationship=UDF模板已存在关联关系,不允许删除
operate.failed=操作失败
test.connection.failed=测试连接失败
switching.tenant.success=选择租户成功
tenant.name.not.exist=租户不存在
job.instance.not.exist=作业实例不存在
modify.success=修改成功
user.old.password.incorrect=用户旧密码不正确
ldap.user.incorrect=LDAP用户名（DN）不正确
role.binding.row.permission=该角色已绑定行权限，无法删除

# dinky-admin
unknown.i18n=未知 i18n 信息,请检查. . .

file.upload.failed=文件上传失败, 原因: {0}
file.rename.failed=文件重命名失败, 原因: {0}
file.delete.failed=文件删除失败, 原因: {0}
file.read.failed=文件读取失败, 原因: {0}

daemon.task.config.not.exist=线程任务配置不能为空
daemon.task.not.support=不支持线程任务类型：

# dinky-alert
alert.rule.jobFail=作业失败
alert.rule.getJobInfoFail=获取作业信息失败
alert.rule.jobRestart=作业重启
alert.rule.checkpointFail=checkpoint失败
alert.rule.jobRunException=作业运行异常
alert.rule.checkpointTimeout=checkpoint超时


# system config
sys.flink.settings.useRestAPI=使用 Rest API
sys.flink.settings.useRestAPI.note=在运维 Flink 任务时是否使用 RestAPI
sys.flink.settings.jobIdWait=Job 提交等待时间
sys.flink.settings.jobIdWait.note=提交 Application 或 PerJob 任务时获取 Job ID 的最大等待时间（秒）
sys.maven.settings.settingsFilePath=Maven 配置文件路径
sys.maven.settings.settingsFilePath.note=Maven 配置文件路径, eg: /opt/maven-3.9.2/conf/settings.xml ,请注意: 默认情况下会获取所在主机的 MAVEN_HOME 环境变量,则此处无需填写,如果没有配置请填写绝对路径
sys.maven.settings.repository=Maven 仓库地址
sys.maven.settings.repository.note=Maven 仓库地址
sys.maven.settings.repositoryUser=Maven 仓库用户名
sys.maven.settings.repositoryUser.note=Maven 私服认证用户名,如果需要配置 Maven 私服仓库认证信息,请填写此项
sys.maven.settings.repositoryPassword=Maven 仓库密码
sys.maven.settings.repositoryPassword.note=Maven 私服认证密码,如果需要配置 Maven 私服仓库认证信息,请填写此项
sys.env.settings.pythonHome=Python 环境变量
sys.env.settings.pythonHome.note=Python 环境变量,用于提交 Python 任务以及构建 Python Udf
sys.env.settings.dinkyAddr=Dinky 地址
sys.env.settings.dinkyAddr.note=该地址为可访问的 Dinky 地址，如 http://127.0.0.1:8888
sys.env.settings.jobResendDiffSecond=告警防重发间隔
sys.env.settings.jobResendDiffSecond.note=在此间隔内,发送告警信息达到 [告警防重发最大条数] 配置的值时,达到阈值后,不再发送告警信息; 单位：秒
sys.env.settings.diffMinuteMaxSendCount=告警防重发最大条数
sys.env.settings.diffMinuteMaxSendCount.note=此配置用于在 [告警防重发间隔] 配置的指定间隔内,发送了 N 次告警信息,达到此配置设置的最大条数后,不再发送告警信息,注意: 此配置以[任务实例+告警策略]为维度,即: 每个[任务实例+告警策略]组合都会单独计算
sys.env.settings.maxRetainDays=作业历史最大保留天数
sys.env.settings.maxRetainDays.note=提交的作业历史与自动注册的集群记录最大保留天数，过期会被自动删除
sys.env.settings.maxRetainCount=作业历史最大保留数量
sys.env.settings.maxRetainCount.note=提交的作业历史与自动注册的集群记录最大保留数量，如果不足该数量，则不会被删除，即使已经过了最大保留天数

sys.dolphinscheduler.settings.enable=是否启用 DolphinScheduler
sys.dolphinscheduler.settings.enable.note=是否启用 DolphinScheduler ,启用后才能使用 DolphinScheduler 的相关功能,请先填写下列配置项,完成后再开启此项配置, 另:请确保 DolphinScheduler 的相关配置正确
sys.dolphinscheduler.settings.url=DolphinScheduler 地址
sys.dolphinscheduler.settings.url.note=地址必须和DolphinScheduler后台配置的地址一致，eg: http://127.0.0.1:12345/dolphinscheduler
sys.dolphinscheduler.settings.token=DolphinScheduler Token
sys.dolphinscheduler.settings.token.note=DolphinScheduler的Token，请在DolphinScheduler的安全中心->令牌管理中创建一个token，并填入该配置中
sys.dolphinscheduler.settings.projectName=DolphinScheduler 项目名
sys.dolphinscheduler.settings.projectName.note=DolphinScheduler 中指定的项目名称，不区分大小写
sys.ldap.settings.url=Ldap 服务地址
sys.ldap.settings.url.note=Ldap 认证服务地址，例如：ldap://192.168.111.1:389
sys.ldap.settings.userDn=登录用户名（DN）
sys.ldap.settings.userDn.note=用于连接 Ldap 服务的用户名，或者管理员DN
sys.ldap.settings.userPassword=登录密码
sys.ldap.settings.userPassword.note=用于连接ldap服务的密码
sys.ldap.settings.timeLimit=连接超时
sys.ldap.settings.timeLimit.note=连接 Ldap 服务的最大时间，超过则断开
sys.ldap.settings.baseDn=用户基础 DN
sys.ldap.settings.baseDn.note=Dinky 会在此基础 DN 下进行用户搜索,例如：ou=users,dc=dinky,dc=com
sys.ldap.settings.filter=用户过滤规则
sys.ldap.settings.filter.note=使用 Ldap 的 filter 语法进行用户过滤
sys.ldap.settings.autoload=登录时自动映射用户
sys.ldap.settings.autoload.note=开启后，当用户使用 LDAP 登录时，如果没有相应的 Dinky 用户映射，则会自动拉取 LDAP 信息创建一个 Dinky 用户与之映射，如果关闭此功能，对于未导入的 LDAP 用户将无法登录
sys.ldap.settings.defaultTeant=LDAP 导入默认租户编码
sys.ldap.settings.defaultTeant.note=开启自动导入用户后，新用户登录需要一个默认的租户编码，否则无法登录,例如: DefaultTenant
sys.ldap.settings.castUsername=LDAP 用户名字段
sys.ldap.settings.castUsername.note=需要填写一个 LDAP 中用户的属性字段来与 Dinky 用户对应，必须填写，一般可选为 cn 或者 uid表示用户唯一标识
sys.ldap.settings.castNickname=LDAP 昵称字段
sys.ldap.settings.castNickname.note=需要填写一个 LDAP 中用户的属性字段来与 Dinky 昵称对应，必须填写，一般可选为 sn 或者其他标识，不要求唯一
sys.ldap.settings.enable=是否启用 Ldap
sys.ldap.settings.enable.note=开启 LDAP 登录功能
sys.metrics.settings.sys.enable=Dinky JVM Monitor 开关
sys.metrics.settings.sys.enable.note=此开关会关系到Dinky JVM Monitor，决定监控页面中的Dinky Server显示，以及JVM Metrics采集
sys.metrics.settings.sys.gatherTiming=Dinky JVM Metrics 采集时间粒度
sys.metrics.settings.sys.gatherTiming.note=Dinky JVM Metrics 采集时间粒度，定时任务间隔触发
sys.metrics.settings.flink.gatherTiming=Flink Metrics 采集时间粒度
sys.metrics.settings.flink.gatherTiming.note=Flink Metrics 采集时间粒度，定时任务间隔触发
sys.metrics.settings.flink.gatherTimeout=Flink Metrics 采集时间粒度，定时任务间隔触发
sys.metrics.settings.flink.gatherTimeout.note=Flink Metrics 采集超时时长，定时任务间隔触发（此配置项应小于Flink Metrics 采集时间粒度）
sys.resource.settings.base.enable=是否启用Resource
sys.resource.settings.base.enable.note=启用资源管理功能，如果切换存储模式时，需关闭此开关，相关配置完成后，再开启
sys.resource.settings.base.upload.base.path=上传目录的根路径
sys.resource.settings.base.upload.base.path.note=资源存储在HDFS/OSS (S3)路径上，资源文件将存储到此基本路径，自行配置，请确保该目录存在于相关存储系统上并具有读写权限。
sys.resource.settings.base.model=存储模式
sys.resource.settings.base.model.note=支持HDFS、S3(Minio、阿里云OSS、腾讯云COS等..)，切换选项后即可生效

sys.resource.settings.oss.endpoint=对象存储服务的 URL（Endpoint）
sys.resource.settings.oss.endpoint.note=例如：https://oss-cn-hangzhou.aliyuncs.com
sys.resource.settings.oss.accessKey=Access key
sys.resource.settings.oss.accessKey.note=Access key就像用户ID，可以唯一标识你的账户
sys.resource.settings.oss.secretKey=Secret key
sys.resource.settings.oss.secretKey.note=Secret key是你账户的密码
sys.resource.settings.oss.bucketName=存储桶名称
sys.resource.settings.oss.bucketName.note=默认的存储桶名称
sys.resource.settings.oss.region=区域
sys.resource.settings.oss.region.note=区域,例如：oss-cn-hangzhou
sys.resource.settings.oss.path.style.access=Path Style
sys.resource.settings.oss.path.style.access.note=是否开启 path style, 不同的提供方（如阿里云oss，腾讯云cos）支持情况不同，请阅读提供方文档说明进行填写

sys.resource.settings.hdfs.root.user=HDFS 操作用户名
sys.resource.settings.hdfs.root.user.note=HDFS 操作用户名
sys.resource.settings.hdfs.fs.defaultFS=HDFS defaultFS
sys.resource.settings.hdfs.fs.defaultFS.note=fs.defaultFS 配置项，例如: 远程 HDFS：hdfs://localhost:9000，本地：file:///
sys.resource.settings.hdfs.core.site=core-site.xml
sys.resource.settings.hdfs.core.site.note=core-site.xml配置文件内容，高可用必填
sys.resource.settings.hdfs.hdfs.site=hdfs-site.xml
sys.resource.settings.hdfs.hdfs.site.note=hdfs-site.xml配置文件内容，高可用必填
#Dinky Gateway
gateway.kubernetes.test.failed=测试 Flink 配置失败：

# Task
task.status.is.not.done=当前作业状态未停止，请停止后操作
task.sql.explain.failed=sql解析失败，请检查
task.update.failed=Task更新失败
mode.is.not.allow.select=Application / Pre-Job 模式不允许执行 select 语句, 如需执行此操作, 请切换至 Local、Standalone、Yarn session等模式
operate.not.support.query=[运行] 按钮不支持 select 语句，请切换至 [查询] 按钮 

# process
process.submit.submitTask=提交作业
process.submit.checkSql=检查作业
process.submit.execute=执行作业
process.submit.buildConfig=构建配置信息
process.submit.execute.commSql=执行普通sql
process.submit.execute.flinkSql=执行FlinkSql
process.register.exits=当前任务正在执行，请勿重复提交，如有问题请前往配置中心查看

# resource
resource.root.dir.not.allow.delete=根目录不允许删除
resource.dir.or.file.not.exist=资源目录或文件不存在
file.path.visit.failed=文件路径访问失败,请检查路径在对应存储系统上是否正确/是否存在
resource.hdfs.configuration.error=资源配置错误，未启用HDFS
resource.oss.configuration.error=资源配置错误，未启用OSS
resource.root.dir.not.exist=根目录不存在，请检查数据库
resource.folder.exists=文件夹已存在