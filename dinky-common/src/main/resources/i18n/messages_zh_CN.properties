test.connection.success=测试连接成功
assign.menu.failed=分配菜单失败
ldap.user.autoload.forbaid=未开启自动映射LDAP用户，请联系管理员导入
cluster.instance.recycle.success=回收成功
execute.failed=执行失败
ldap.user.duplicat=ldap匹配到多个用户数据
git.branch.not.found=获取不到分支信息
copy.success=复制成功
user.superadmin.cannot.disable=超级管理员用户不能停用
ds.work.flow.not.save=请先保存工作流
schedule.status.unknown=未知状态: {0}
user.binding.role.delete.all=用户绑定角色删除所有
modify.failed=修改失败
git.build.success=构建成功
menu.has.child=存在子菜单 不允许删除
tenant.already.exists=租户已存在
save.failed=保存失败
assign.menu.success=分配菜单成功
user.disabled.by.admin=当前用户已被管理员停用
select.menu=请选择菜单
role.not.exist=角色不存在
delete.success=删除成功
clear.success=清除成功
move.success=移动成功
ldap.login.forbid=当前用户登录模式不是LDAP，请联系管理员修改,或不使用LDAP登录
request.params.not.valid.error=请求参数[{0}]无效
change.password.failed=修改密码失败
menu.name.exist=菜单已存在
ds.task.type.not.support=海豚调度类型为 [{}] 不支持,非DINKY类型
datasource.connect.normal=数据源连接正常
restart.success=重启成功
test.msg.job.log.url=点击查看该任务的异常日志
user.assign.role.success=用户分配角色成功
global.params.check.error.value=字段: {0}, 不合法的值: {1}
change.password.success=修改密码成功
user.not.exist=用户不存在
refresh.success=刷新成功
ds.get.node.list.error=节点获取失败
ldap.default.tenant.nofound=LDAP默认租户不存在
copy.failed=复制失败
folder.not.empty=该目录下存在子目录/作业，无法删除
be.replaced=token 已被顶下线
datasource.connect.success=数据源连接测试成功
sign.out.success=退出成功
added.success=新增成功
tenant.binding.user=删除租户失败，该租户已绑定用户
send.test.failed=测试信息发送失败
delete.failed=删除失败
role.binding.user=该角色已绑定用户，无法删除
not.token=未能读取到有效 Token
execute.success=执行成功
token.freezed=token 已被冻结
menu.has.assign=菜单已分配,不允许删除
datasource.status.refresh.success=数据源状态刷新成功
user.not.login=用户未登录
tenant.assign.user.failed=分配用户失败
stop.success=已成功停止
move.failed=移动失败
get.tenant.failed=获取租户信息失败
send.test.success=测试信息发送成功
login.success=登录成功
login.password.not.null=登录密码不能为空
unknown.error=未知异常: {0}
stop.failed=停止失败
role.name.exist=角色已存在
ldap.filter.incorrect=用户过滤规则不能为空，请填写相关配置
tenant.assign.user.success=分配用户成功
ds.add.work.flow.definition.success=添加工作流定义成功
expired.token=Token 已过期
refresh.failed=刷新失败
operate.success=操作成功
git.project.not.found=获取不到项目信息
cluster.instance.heartbeat.success=集群实例心跳成功
ldap.no.user.found=LDAP连接成功，但未匹配到任何用户
login.failure=用户登录失败
request.params.error=请求参数错误
user.not.binding.tenant=用户未绑定租户
user.assign.role.failed=用户分配角色失败
rename.failed=重命名失败
test.msg.job.name=测试任务
tenant.binding.user.delete.all=该租户绑定的用户已被全部删除
menu.not.exist=菜单不存在
test.msg.job.name.title=任务
ds.task.not.exist=任务不存在
global.params.check.error=字段: {0}, {1}
test.msg.title=实时告警监控
user.name.passwd.error=用户名或密码不正确
no.prefix=未按照指定前缀提交 token
query.success=查询成功
ds.work.flow.definition.not.exist=工作流定义不存在
tenant.name.exist=租户已存在
failed=获取失败
added.failed=新增失败
task.not.exist=任务不存在
task.is.online=任务已上线，禁止修改
cluster.instance.deploy=部署完成
clear.failed=清除失败
rename.success=重命名成功
job.release.disabled.update=作业已发布，禁止修改
success=获取成功
tenant.not.exist=租户不存在
user.already.exists=用户名已存在
git.building=此任务正在构建
ds.work.flow.definition.task.name.exist=添加失败,工作流定义 [{}] 已存在任务定义 [{}] 请刷新
role.already.exists=角色已存在
internal.server.error.args=服务端异常: {0}
kick.out=token 已被踢下线
restart.failed=重启失败
invalid.token=无效的 Token
datasource.not.exist=数据源不存在
datasource.clear.cache.success=清除库表缓存成功
tenant.admin.already.exists=已存在租户管理员, 租户超管只能有一个
ds.work.flow.definition.online=工作流定义 [{}] 已经上线
test.msg.job.url=跳转至该任务
savepoint.is.null=保存点为空
git.sort.success=排序成功
ds.add.task.definition.success=添加任务定义成功
alert.group.exist=告警组已存在
git.sort.failed=排序失败
query.failed=查询失败
save.success=保存成功
cluster.instance.kill=已杀死该进程/集群
cluster.not.exist=集群不存在
operate.failed=操作失败
test.connection.failed=测试连接失败
switching.tenant.success=选择租户成功
tenant.name.not.exist=租户不存在
job.instance.not.exist=作业实例不存在
modify.success=修改成功
user.old.password.incorrect=用户旧密码不正确
ldap.user.incorrect=LDAP用户名（DN）不正确
role.binding.row.permission=该角色已绑定行权限，无法删除

# dinky-admin
unknown.i18n=未知 i18n 信息,请检查. . .

file.upload.failed=文件上传失败, 原因: {0}

hdfs.init.failed=内部hdfs信息错误, 原因: {0}
hdfs.file.lose= 在工程根目录下没有找到core-site.xml/hdfs-site.xml/yarn-site.xml文件, 请先上传这些文件

daemon.task.config.not.exist=线程任务配置不能为空
daemon.task.not.support=不支持线程任务类型：

# dinky-alert
alert.rule.jobFail=作业失败
alert.rule.getJobInfoFail=获取作业信息失败
alert.rule.jobRestart=作业重启
alert.rule.checkpointFail=checkpoint失败
alert.rule.jobRunException=作业运行异常
alert.rule.checkpointTimeout=checkpoint超时


# system config
sys.flink.settings.useRestAPI=使用 Rest API
sys.flink.settings.useRestAPI.note=在运维 Flink 任务时是否使用 RestAPI
sys.flink.settings.sqlSeparator=SQL 分隔符
sys.flink.settings.sqlSeparator.note=SQL 分隔符
sys.flink.settings.jobIdWait=Job 提交等待时间
sys.flink.settings.jobIdWait.note=提交 Application 或 PerJob 任务时获取 Job ID 的最大等待时间（秒）
sys.maven.settings.settingsFilePath=Maven 配置文件路径
sys.maven.settings.settingsFilePath.note=Maven 配置文件路径, eg
sys.maven.settings.repository=Maven 仓库地址
sys.maven.settings.repository.note=Maven 仓库地址
sys.maven.settings.repositoryUser=Maven 仓库用户名
sys.maven.settings.repositoryUser.note=Maven 私服认证用户名
sys.maven.settings.repositoryPassword=Maven 仓库密码
sys.maven.settings.repositoryPassword.note=Maven 私服认证密码,请注意
sys.env.settings.pythonHome=Python 环境变量
sys.env.settings.pythonHome.note=Python 环境变量
sys.env.settings.dinkyAddr=Dinky 地址
sys.env.settings.dinkyAddr.note=该地址必须与Dinky Application后台url中配置的地址相同
sys.dolphinscheduler.settings.enable=是否启用 DolphinScheduler
sys.dolphinscheduler.settings.enable.note=是否启用 DolphinScheduler ,启用后才能使用 DolphinScheduler 的相关功能, 请确保 DolphinScheduler 的相关配置正确
sys.dolphinscheduler.settings.url=DolphinScheduler 地址
sys.dolphinscheduler.settings.url.note=地址必须和DolphinScheduler后台配置的地址一致，eg: http://127.0.0.1:12345/dolphinscheduler
sys.dolphinscheduler.settings.token=DolphinScheduler Token
sys.dolphinscheduler.settings.token.note=DolphinScheduler的Token，请在DolphinScheduler的安全中心->令牌管理中创建一个token，并填入该配置中
sys.dolphinscheduler.settings.projectName=DolphinScheduler 项目名
sys.dolphinscheduler.settings.projectName.note=DolphinScheduler 中指定的项目名称，不区分大小写
sys.ldap.settings.url=ldap服务地址
sys.ldap.settings.url.note=ldap认证服务地址，例如：ldap://192.168.111.1:389
sys.ldap.settings.userDn=登录用户名（DN）
sys.ldap.settings.userDn.note=用于连接ldap服务的用户名，或者管理员DN
sys.ldap.settings.userPassword=登录密码
sys.ldap.settings.userPassword.note=用于连接ldap服务的密码
sys.ldap.settings.timeLimit=连接超时
sys.ldap.settings.timeLimit.note=连接ldap服务的最大时间，超过则断开
sys.ldap.settings.baseDn=用户基础DN
sys.ldap.settings.baseDn.note=Dinky会在此基础dn下进行用户搜索,例如：ou=users,dc=dinky,dc=com
sys.ldap.settings.filter=用户过滤规则
sys.ldap.settings.filter.note=使用ldap的filter语法进行用户过滤，例如
sys.ldap.settings.autoload=登录时自动映射用户
sys.ldap.settings.autoload.note=开启后，当用户使用LDAP登录时，如果没有相应的Dinky用户映射，则会自动拉取LDAP信息创建一个Dinky用户与之映射，如果关闭此功能，对于未导入的LDAP用户将无法登录
sys.ldap.settings.defaultTeant=LDAP导入默认租户编码
sys.ldap.settings.defaultTeant.note=开启自动导入用户后，新用户登录需要一个默认的租户编码，否则无法登录
sys.ldap.settings.castUsername=LDAP用户名字段
sys.ldap.settings.castUsername.note=需要填写一个LDAP中用户的属性字段来与Dinky用户对应，必须填写，一般可选为 cn 或者 uid表示用户唯一标识
sys.ldap.settings.castNickname=LDAP昵称字段
sys.ldap.settings.castNickname.note=需要填写一个LDAP中用户的属性字段来与Dinky昵称对应，必须填写，一般可选为 sn 或者其他标识，不要求唯一
sys.ldap.settings.enable=是否启用ldap
sys.ldap.settings.enable.note=开启LDAP登录功能
sys.metrics.settings.sys.enable=Dinky JVM Monitor 开关
sys.metrics.settings.sys.enable.note=此开关会关系到Dinky JVM Monitor，决定监控页面中的Dinky Server显示，以及JVM Metrics采集
sys.metrics.settings.sys.gatherTiming=Dinky JVM Metrics 采集时间粒度
sys.metrics.settings.sys.gatherTiming.note=Dinky JVM Metrics 采集时间粒度，定时任务间隔触发
sys.metrics.settings.flink.gatherTiming=Flink Metrics 采集时间粒度
sys.metrics.settings.flink.gatherTiming.note=Flink Metrics 采集时间粒度，定时任务间隔触发
sys.metrics.settings.flink.gatherTimeout=Flink Metrics 采集时间粒度，定时任务间隔触发
sys.metrics.settings.flink.gatherTimeout.note=Flink Metrics 采集超时时长，定时任务间隔触发（此配置项应小于Flink Metrics 采集时间粒度）
sys.resource.settings.enable=是否启用Resource
sys.resource.settings.enable.note=启用资源管理功能，如果切换存储模式时，需关闭此开关，相关配置完成后，再开启
sys.resource.settings.upload.base.path=上传目录的根路径
sys.resource.settings.upload.base.path.note=资源存储在HDFS/OSS路径上，资源文件将存储到此基本路径，自行配置，请确保该目录存在于hdfs上并具有读写权限。推荐
sys.resource.settings.model=存储模式：支持HDFS、OSS
sys.resource.settings.model.note=存储模式：支持HDFS、OSS，切换选项后即可生效，同时并迁移资源文件
sys.resource.settings.oss.endpoint=对象存储服务的URL
sys.resource.settings.oss.endpoint.note=对象存储服务的URL，例如：https://oss-cn-hangzhou.aliyuncs.com
sys.resource.settings.oss.accessKey=Access key就像用户ID，可以唯一标识你的账户
sys.resource.settings.oss.accessKey.note=Access key就像用户ID，可以唯一标识你的账户
sys.resource.settings.oss.secretKey=Secret key是你账户的密码
sys.resource.settings.oss.secretKey.note=Secret key是你账户的密码
sys.resource.settings.oss.bucketName=默认的存储桶名称
sys.resource.settings.oss.bucketName.note=默认的存储桶名称
sys.resource.settings.oss.region=区域
sys.resource.settings.oss.region.note=区域
sys.resource.settings.hdfs.root.user=HDFS操作用户名
sys.resource.settings.hdfs.root.user.note=HDFS操作用户名
sys.resource.settings.hdfs.fs.defaultFS=HDFS defaultFS
sys.resource.settings.hdfs.fs.defaultFS.note=fs.defaultFS 配置项，例如远程：hdfs://localhost:9000，本地：file:///

#Dinky Gateway
gateway.kubernetes.test.failed=测试 Flink 配置失败：

# Task
task.status.is.not.done=当前发布状态下有作业正在运行，上线失败，请停止后上线
task.sql.explain.failed=sql解析失败，请检查
task.update.failed=Task更新失败

# process
process.submit.submitTask=提交作业
process.submit.checkSql=检查作业
process.submit.execute=执行作业
process.submit.buildConfig=构建配置信息
process.submit.execute.commSql=执行普通sql
process.submit.execute.flinkSql=执行flinkSql